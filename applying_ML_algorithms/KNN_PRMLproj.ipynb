{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgarwalMayank2/Face_Detection/blob/KNN_Tavishi/KNN_PRMLproj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s9r-dpHDIufI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RAtDSaH4hp8J"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abJAGmSnaMjK",
        "outputId": "fb52e46a-fcef-4753-f651-47e140da4a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_aCtTzCZ36W"
      },
      "source": [
        "# Reading CNN features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OgLogzTLI2UA"
      },
      "outputs": [],
      "source": [
        "url_filtered_CNN_features_dataset = 'https://raw.githubusercontent.com/AgarwalMayank2/Face_Detection/refs/heads/main/processed_dataset/filtered_CNN_features_dataset.csv' #for CNN limited\n",
        "df_cnn = pd.read_csv(url_filtered_CNN_features_dataset) # reading url for extracted CNN_features_dataset_limited.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "aBBPCP2rI4c2",
        "outputId": "c9164c88-fee9-414e-9f8d-b3306f567b50"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "      <th>2048</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.266585</td>\n",
              "      <td>1.337187</td>\n",
              "      <td>1.352905</td>\n",
              "      <td>0.100848</td>\n",
              "      <td>1.880685</td>\n",
              "      <td>0.059888</td>\n",
              "      <td>2.773605</td>\n",
              "      <td>0.115643</td>\n",
              "      <td>0.138749</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039434</td>\n",
              "      <td>0.071662</td>\n",
              "      <td>0.733759</td>\n",
              "      <td>1.643910</td>\n",
              "      <td>0.041306</td>\n",
              "      <td>1.488236</td>\n",
              "      <td>0.048181</td>\n",
              "      <td>0.247783</td>\n",
              "      <td>0.300232</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.355948</td>\n",
              "      <td>0.750634</td>\n",
              "      <td>0.909794</td>\n",
              "      <td>0.188214</td>\n",
              "      <td>0.680066</td>\n",
              "      <td>0.221442</td>\n",
              "      <td>3.089571</td>\n",
              "      <td>0.342022</td>\n",
              "      <td>0.087186</td>\n",
              "      <td>...</td>\n",
              "      <td>0.093867</td>\n",
              "      <td>0.089694</td>\n",
              "      <td>0.859610</td>\n",
              "      <td>1.764073</td>\n",
              "      <td>0.250430</td>\n",
              "      <td>1.133540</td>\n",
              "      <td>0.004091</td>\n",
              "      <td>0.153542</td>\n",
              "      <td>0.236034</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.267111</td>\n",
              "      <td>1.015316</td>\n",
              "      <td>1.154480</td>\n",
              "      <td>0.131544</td>\n",
              "      <td>1.066389</td>\n",
              "      <td>0.024949</td>\n",
              "      <td>3.701925</td>\n",
              "      <td>0.145037</td>\n",
              "      <td>0.082419</td>\n",
              "      <td>...</td>\n",
              "      <td>0.080086</td>\n",
              "      <td>0.089589</td>\n",
              "      <td>0.663708</td>\n",
              "      <td>1.854499</td>\n",
              "      <td>0.078751</td>\n",
              "      <td>1.240009</td>\n",
              "      <td>0.065222</td>\n",
              "      <td>0.105058</td>\n",
              "      <td>0.227633</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.260295</td>\n",
              "      <td>0.882900</td>\n",
              "      <td>0.885955</td>\n",
              "      <td>0.106698</td>\n",
              "      <td>2.663052</td>\n",
              "      <td>0.057836</td>\n",
              "      <td>1.854394</td>\n",
              "      <td>0.209269</td>\n",
              "      <td>0.103750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.181255</td>\n",
              "      <td>0.182038</td>\n",
              "      <td>0.397535</td>\n",
              "      <td>1.222931</td>\n",
              "      <td>0.007285</td>\n",
              "      <td>0.878194</td>\n",
              "      <td>0.016247</td>\n",
              "      <td>0.110492</td>\n",
              "      <td>0.129523</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.347203</td>\n",
              "      <td>0.623839</td>\n",
              "      <td>0.817085</td>\n",
              "      <td>0.212599</td>\n",
              "      <td>1.026321</td>\n",
              "      <td>0.176634</td>\n",
              "      <td>2.486715</td>\n",
              "      <td>0.426571</td>\n",
              "      <td>0.345026</td>\n",
              "      <td>...</td>\n",
              "      <td>0.267895</td>\n",
              "      <td>0.136346</td>\n",
              "      <td>0.713298</td>\n",
              "      <td>0.978184</td>\n",
              "      <td>0.059828</td>\n",
              "      <td>1.008205</td>\n",
              "      <td>0.042905</td>\n",
              "      <td>0.028597</td>\n",
              "      <td>0.199120</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.354952</td>\n",
              "      <td>0.935169</td>\n",
              "      <td>1.313525</td>\n",
              "      <td>0.161971</td>\n",
              "      <td>0.743334</td>\n",
              "      <td>0.075382</td>\n",
              "      <td>2.913061</td>\n",
              "      <td>0.339807</td>\n",
              "      <td>0.038969</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042886</td>\n",
              "      <td>0.094991</td>\n",
              "      <td>0.731441</td>\n",
              "      <td>1.846496</td>\n",
              "      <td>0.061113</td>\n",
              "      <td>0.960774</td>\n",
              "      <td>0.152283</td>\n",
              "      <td>0.094486</td>\n",
              "      <td>0.294108</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.491479</td>\n",
              "      <td>1.098953</td>\n",
              "      <td>0.935011</td>\n",
              "      <td>0.099713</td>\n",
              "      <td>0.859047</td>\n",
              "      <td>0.125197</td>\n",
              "      <td>2.448608</td>\n",
              "      <td>0.194795</td>\n",
              "      <td>0.171454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.197234</td>\n",
              "      <td>0.036094</td>\n",
              "      <td>0.552411</td>\n",
              "      <td>1.532099</td>\n",
              "      <td>0.195461</td>\n",
              "      <td>0.562803</td>\n",
              "      <td>0.054066</td>\n",
              "      <td>0.242185</td>\n",
              "      <td>0.097366</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.076298</td>\n",
              "      <td>1.872830</td>\n",
              "      <td>1.156564</td>\n",
              "      <td>0.151697</td>\n",
              "      <td>1.786531</td>\n",
              "      <td>0.004271</td>\n",
              "      <td>2.473813</td>\n",
              "      <td>0.183758</td>\n",
              "      <td>0.190911</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025632</td>\n",
              "      <td>0.110004</td>\n",
              "      <td>0.524370</td>\n",
              "      <td>1.041115</td>\n",
              "      <td>0.171625</td>\n",
              "      <td>1.456280</td>\n",
              "      <td>0.096045</td>\n",
              "      <td>0.074930</td>\n",
              "      <td>0.214463</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.443961</td>\n",
              "      <td>1.489843</td>\n",
              "      <td>1.034748</td>\n",
              "      <td>0.054299</td>\n",
              "      <td>1.201338</td>\n",
              "      <td>0.475425</td>\n",
              "      <td>3.003049</td>\n",
              "      <td>0.170383</td>\n",
              "      <td>0.172904</td>\n",
              "      <td>...</td>\n",
              "      <td>0.170266</td>\n",
              "      <td>0.155772</td>\n",
              "      <td>1.335769</td>\n",
              "      <td>1.501814</td>\n",
              "      <td>0.096764</td>\n",
              "      <td>1.345042</td>\n",
              "      <td>0.470579</td>\n",
              "      <td>0.327874</td>\n",
              "      <td>0.116694</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.265048</td>\n",
              "      <td>1.558320</td>\n",
              "      <td>0.774199</td>\n",
              "      <td>0.302818</td>\n",
              "      <td>0.905585</td>\n",
              "      <td>0.152244</td>\n",
              "      <td>2.703004</td>\n",
              "      <td>0.314053</td>\n",
              "      <td>0.539273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.076195</td>\n",
              "      <td>0.142454</td>\n",
              "      <td>0.670869</td>\n",
              "      <td>1.724953</td>\n",
              "      <td>0.110348</td>\n",
              "      <td>1.263562</td>\n",
              "      <td>0.008221</td>\n",
              "      <td>0.099455</td>\n",
              "      <td>0.174265</td>\n",
              "      <td>Paul_Bremer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 2050 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0         1         2         3         4         5  \\\n",
              "0           0  0.266585  1.337187  1.352905  0.100848  1.880685  0.059888   \n",
              "1           1  0.355948  0.750634  0.909794  0.188214  0.680066  0.221442   \n",
              "2           2  0.267111  1.015316  1.154480  0.131544  1.066389  0.024949   \n",
              "3           3  0.260295  0.882900  0.885955  0.106698  2.663052  0.057836   \n",
              "4           4  0.347203  0.623839  0.817085  0.212599  1.026321  0.176634   \n",
              "5           5  0.354952  0.935169  1.313525  0.161971  0.743334  0.075382   \n",
              "6           6  0.491479  1.098953  0.935011  0.099713  0.859047  0.125197   \n",
              "7           7  0.076298  1.872830  1.156564  0.151697  1.786531  0.004271   \n",
              "8           8  0.443961  1.489843  1.034748  0.054299  1.201338  0.475425   \n",
              "9           9  0.265048  1.558320  0.774199  0.302818  0.905585  0.152244   \n",
              "\n",
              "          6         7         8  ...      2039      2040      2041      2042  \\\n",
              "0  2.773605  0.115643  0.138749  ...  0.039434  0.071662  0.733759  1.643910   \n",
              "1  3.089571  0.342022  0.087186  ...  0.093867  0.089694  0.859610  1.764073   \n",
              "2  3.701925  0.145037  0.082419  ...  0.080086  0.089589  0.663708  1.854499   \n",
              "3  1.854394  0.209269  0.103750  ...  0.181255  0.182038  0.397535  1.222931   \n",
              "4  2.486715  0.426571  0.345026  ...  0.267895  0.136346  0.713298  0.978184   \n",
              "5  2.913061  0.339807  0.038969  ...  0.042886  0.094991  0.731441  1.846496   \n",
              "6  2.448608  0.194795  0.171454  ...  0.197234  0.036094  0.552411  1.532099   \n",
              "7  2.473813  0.183758  0.190911  ...  0.025632  0.110004  0.524370  1.041115   \n",
              "8  3.003049  0.170383  0.172904  ...  0.170266  0.155772  1.335769  1.501814   \n",
              "9  2.703004  0.314053  0.539273  ...  0.076195  0.142454  0.670869  1.724953   \n",
              "\n",
              "       2043      2044      2045      2046      2047         2048  \n",
              "0  0.041306  1.488236  0.048181  0.247783  0.300232  Paul_Bremer  \n",
              "1  0.250430  1.133540  0.004091  0.153542  0.236034  Paul_Bremer  \n",
              "2  0.078751  1.240009  0.065222  0.105058  0.227633  Paul_Bremer  \n",
              "3  0.007285  0.878194  0.016247  0.110492  0.129523  Paul_Bremer  \n",
              "4  0.059828  1.008205  0.042905  0.028597  0.199120  Paul_Bremer  \n",
              "5  0.061113  0.960774  0.152283  0.094486  0.294108  Paul_Bremer  \n",
              "6  0.195461  0.562803  0.054066  0.242185  0.097366  Paul_Bremer  \n",
              "7  0.171625  1.456280  0.096045  0.074930  0.214463  Paul_Bremer  \n",
              "8  0.096764  1.345042  0.470579  0.327874  0.116694  Paul_Bremer  \n",
              "9  0.110348  1.263562  0.008221  0.099455  0.174265  Paul_Bremer  \n",
              "\n",
              "[10 rows x 2050 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cnn.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU_KWQ0XjO7K"
      },
      "source": [
        "# Train/Test split - for CNN dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOdOJRPmJXLk",
        "outputId": "6d2a2578-d6e1-4fbc-ccb2-4969905fab56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: (4324, 2050)\n",
            "Training size: (3459, 2049), Testing size: (865, 2049)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and labels\n",
        "X_cnn = df_cnn.iloc[:, :-1]\n",
        "y_cnn = df_cnn.iloc[:, -1]\n",
        "\n",
        "# Encode labels (alphabetically)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_cnn)\n",
        "# encoding is benificial as working on numbers is lot easier than working on string\n",
        "\n",
        "# Ensure stratified split (16 training, 4 testing per class)\n",
        "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_encoded, test_size=1/5, random_state=42, stratify=y_encoded)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_cnn = scaler.fit_transform(X_train_cnn)\n",
        "X_test_cnn = scaler.transform(X_test_cnn)\n",
        "\n",
        "print(f\"Dataset size: {df_cnn.shape}\")\n",
        "print(f\"Training size: {X_train_cnn.shape}, Testing size: {X_test_cnn.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ivBo4geM414",
        "outputId": "135c62af-09a9-4ebd-cf4e-6836c2c3d841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 36 134 146   6  41  23  61  28 134  53]\n"
          ]
        }
      ],
      "source": [
        "print(y_train_cnn[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME1Ya2JxZ8Gr"
      },
      "source": [
        "# Reading HoG features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ilp3kobSaBeW"
      },
      "outputs": [],
      "source": [
        "url_filtered_HoG_features_dataset=\"C:/Users/tavis/Downloads/filtered_HOG_features_dataset.csv\"\n",
        "df_hog=pd.read_csv(url_filtered_HoG_features_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JDGUurVfdCf2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>70299</th>\n",
              "      <th>70300</th>\n",
              "      <th>70301</th>\n",
              "      <th>70302</th>\n",
              "      <th>70303</th>\n",
              "      <th>70304</th>\n",
              "      <th>70305</th>\n",
              "      <th>70306</th>\n",
              "      <th>70307</th>\n",
              "      <th>70308</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.147622</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010496</td>\n",
              "      <td>0.01048</td>\n",
              "      <td>0.030300</td>\n",
              "      <td>0.008548</td>\n",
              "      <td>0.005577</td>\n",
              "      <td>0.006585</td>\n",
              "      <td>0.021226</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020418</td>\n",
              "      <td>0.009971</td>\n",
              "      <td>0.008646</td>\n",
              "      <td>0.014164</td>\n",
              "      <td>0.049468</td>\n",
              "      <td>0.003930</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.006818</td>\n",
              "      <td>0.021222</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.132761</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.002665</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.202144</td>\n",
              "      <td>0.032098</td>\n",
              "      <td>0.033961</td>\n",
              "      <td>0.02799</td>\n",
              "      <td>0.317099</td>\n",
              "      <td>0.058462</td>\n",
              "      <td>0.033903</td>\n",
              "      <td>0.034219</td>\n",
              "      <td>0.166567</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.026542</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.151645</td>\n",
              "      <td>0.034494</td>\n",
              "      <td>0.074602</td>\n",
              "      <td>0.105946</td>\n",
              "      <td>0.305386</td>\n",
              "      <td>0.050689</td>\n",
              "      <td>0.037455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018227</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 70310 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0         1         2        3         4         5  \\\n",
              "0           0  0.147622  0.000000  0.010496  0.01048  0.030300  0.008548   \n",
              "1           1  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "2           2  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "3           3  0.132761  0.000000  0.000000  0.00000  0.002665  0.000000   \n",
              "4           4  0.202144  0.032098  0.033961  0.02799  0.317099  0.058462   \n",
              "5           5  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "6           6  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "7           7  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "8           8  0.026542  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "9           9  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000   \n",
              "\n",
              "          6         7         8  ...     70299     70300     70301     70302  \\\n",
              "0  0.005577  0.006585  0.021226  ...  0.020418  0.009971  0.008646  0.014164   \n",
              "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "4  0.033903  0.034219  0.166567  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "5  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "6  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "7  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "8  0.000000  0.000000  0.000000  ...  0.151645  0.034494  0.074602  0.105946   \n",
              "9  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
              "\n",
              "      70303     70304     70305     70306     70307       70308  \n",
              "0  0.049468  0.003930  0.001001  0.006818  0.021222  Tim_Henman  \n",
              "1  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "2  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "3  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "4  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "5  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "6  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "7  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "8  0.305386  0.050689  0.037455  0.000000  0.018227  Tim_Henman  \n",
              "9  0.000000  0.000000  0.000000  0.000000  0.000000  Tim_Henman  \n",
              "\n",
              "[10 rows x 70310 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_hog.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj0cyKMBjMz5"
      },
      "source": [
        "# Train/Test split - for HoG dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RdfVYz72dG0B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: (4324, 70310)\n",
            "Training size: (3459, 70309), Testing size: (865, 70309)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and labels\n",
        "X_hog = df_hog.iloc[:, :-1]\n",
        "y_hog = df_hog.iloc[:, -1]\n",
        "\n",
        "# Encode labels (alphabetically)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_hog)\n",
        "# encoding is benificial as working on numbers is lot easier than working on string\n",
        "\n",
        "# Ensure stratified split (16 training, 4 testing per class)\n",
        "X_train_hog, X_test_hog, y_train_hog, y_test_hog = train_test_split(X_hog, y_encoded, test_size=1/5, random_state=42, stratify=y_encoded)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_hog = scaler.fit_transform(X_train_hog)\n",
        "X_test_hog = scaler.transform(X_test_hog)\n",
        "\n",
        "print(f\"Dataset size: {df_hog.shape}\")\n",
        "print(f\"Training size: {X_train_hog.shape}, Testing size: {X_test_hog.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CLgbYhXifZq"
      },
      "source": [
        "# Reading LBP features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PfPbJMxQie_9"
      },
      "outputs": [],
      "source": [
        "url_filtered_lbp_features = 'https://raw.githubusercontent.com/AgarwalMayank2/Face_Detection/refs/heads/main/processed_dataset/filtered_LBP_features_dataset.csv'\n",
        "df_LBP = pd.read_csv(url_filtered_lbp_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "1Aq-5GLCi9nk",
        "outputId": "f4ba2512-cb36-4c2f-d123-377b816b548b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>589.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>466.0</td>\n",
              "      <td>370.0</td>\n",
              "      <td>...</td>\n",
              "      <td>474.0</td>\n",
              "      <td>1924.0</td>\n",
              "      <td>612.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>592.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>6088.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1012.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>383.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>205.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>505.0</td>\n",
              "      <td>...</td>\n",
              "      <td>591.0</td>\n",
              "      <td>2086.0</td>\n",
              "      <td>681.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>447.0</td>\n",
              "      <td>699.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>486.0</td>\n",
              "      <td>13472.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>920.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>152.0</td>\n",
              "      <td>107.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>403.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>...</td>\n",
              "      <td>461.0</td>\n",
              "      <td>1812.0</td>\n",
              "      <td>579.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>597.0</td>\n",
              "      <td>411.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>11673.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1068.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>447.0</td>\n",
              "      <td>298.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>293.0</td>\n",
              "      <td>732.0</td>\n",
              "      <td>546.0</td>\n",
              "      <td>...</td>\n",
              "      <td>727.0</td>\n",
              "      <td>2150.0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>564.0</td>\n",
              "      <td>585.0</td>\n",
              "      <td>367.0</td>\n",
              "      <td>5449.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>510.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>...</td>\n",
              "      <td>405.0</td>\n",
              "      <td>3263.0</td>\n",
              "      <td>588.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>307.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>4606.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>678.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>...</td>\n",
              "      <td>366.0</td>\n",
              "      <td>2675.0</td>\n",
              "      <td>577.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>556.0</td>\n",
              "      <td>678.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>581.0</td>\n",
              "      <td>17998.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>668.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>347.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>...</td>\n",
              "      <td>510.0</td>\n",
              "      <td>2106.0</td>\n",
              "      <td>678.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>612.0</td>\n",
              "      <td>660.0</td>\n",
              "      <td>435.0</td>\n",
              "      <td>639.0</td>\n",
              "      <td>13194.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>745.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>363.0</td>\n",
              "      <td>376.0</td>\n",
              "      <td>...</td>\n",
              "      <td>590.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>622.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>410.0</td>\n",
              "      <td>380.0</td>\n",
              "      <td>9406.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>428.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>268.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>430.0</td>\n",
              "      <td>265.0</td>\n",
              "      <td>...</td>\n",
              "      <td>343.0</td>\n",
              "      <td>1964.0</td>\n",
              "      <td>668.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>537.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>283.0</td>\n",
              "      <td>3225.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1154.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>354.0</td>\n",
              "      <td>234.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>473.0</td>\n",
              "      <td>...</td>\n",
              "      <td>578.0</td>\n",
              "      <td>1488.0</td>\n",
              "      <td>599.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>587.0</td>\n",
              "      <td>482.0</td>\n",
              "      <td>399.0</td>\n",
              "      <td>11423.0</td>\n",
              "      <td>Tim_Henman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0       0      1      2      3      4     5      6      7      8  \\\n",
              "0           0   589.0   57.0  319.0  205.0   67.0   4.0  195.0  466.0  370.0   \n",
              "1           1  1012.0  113.0  383.0  203.0   76.0  11.0  205.0  369.0  505.0   \n",
              "2           2   920.0   92.0  288.0  152.0  107.0  18.0  192.0  403.0  313.0   \n",
              "3           3  1068.0   85.0  447.0  298.0   90.0  11.0  293.0  732.0  546.0   \n",
              "4           4   510.0   43.0  304.0  189.0   47.0   8.0  201.0  387.0  296.0   \n",
              "5           5   678.0   65.0  173.0  131.0   66.0  14.0  114.0  255.0  292.0   \n",
              "6           6   668.0   62.0  344.0  187.0   60.0  10.0  218.0  347.0  330.0   \n",
              "7           7   745.0   74.0  267.0  218.0   80.0  10.0  180.0  363.0  376.0   \n",
              "8           8   428.0   45.0  268.0  222.0   44.0   6.0  210.0  430.0  265.0   \n",
              "9           9  1154.0  103.0  354.0  234.0  113.0  16.0  260.0  374.0  473.0   \n",
              "\n",
              "   ...    247     248    249   250    251    252    253    254      255  \\\n",
              "0  ...  474.0  1924.0  612.0  26.0  357.0  592.0  523.0  328.0   6088.0   \n",
              "1  ...  591.0  2086.0  681.0  29.0  447.0  699.0  535.0  486.0  13472.0   \n",
              "2  ...  461.0  1812.0  579.0  41.0  428.0  597.0  411.0  374.0  11673.0   \n",
              "3  ...  727.0  2150.0  650.0  32.0  374.0  564.0  585.0  367.0   5449.0   \n",
              "4  ...  405.0  3263.0  588.0  36.0  307.0  593.0  350.0  328.0   4606.0   \n",
              "5  ...  366.0  2675.0  577.0  43.0  556.0  678.0  313.0  581.0  17998.0   \n",
              "6  ...  510.0  2106.0  678.0  51.0  612.0  660.0  435.0  639.0  13194.0   \n",
              "7  ...  590.0  2008.0  622.0  44.0  417.0  545.0  410.0  380.0   9406.0   \n",
              "8  ...  343.0  1964.0  668.0  35.0  315.0  537.0  433.0  283.0   3225.0   \n",
              "9  ...  578.0  1488.0  599.0  30.0  396.0  587.0  482.0  399.0  11423.0   \n",
              "\n",
              "          256  \n",
              "0  Tim_Henman  \n",
              "1  Tim_Henman  \n",
              "2  Tim_Henman  \n",
              "3  Tim_Henman  \n",
              "4  Tim_Henman  \n",
              "5  Tim_Henman  \n",
              "6  Tim_Henman  \n",
              "7  Tim_Henman  \n",
              "8  Tim_Henman  \n",
              "9  Tim_Henman  \n",
              "\n",
              "[10 rows x 258 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_LBP.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVs6_YoYjCoS"
      },
      "source": [
        "# Train/Test split - for LBP dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abp0KaGlieJZ",
        "outputId": "8007bc84-d1ea-4694-d7b7-9f41931d8b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: (4324, 258)\n",
            "Training size: (3459, 257), Testing size: (865, 257)\n"
          ]
        }
      ],
      "source": [
        "# Separate features and labels\n",
        "X_LBP = df_LBP.iloc[:, :-1]\n",
        "y_LBP = df_LBP.iloc[:, -1]\n",
        "\n",
        "# Encode labels (alphabetically)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_LBP)\n",
        "# encoding is benificial as working on numbers is lot easier than working on string\n",
        "\n",
        "# Ensure stratified split (16 training, 4 testing per class)\n",
        "X_train_LBP, X_test_LBP, y_train_LBP, y_test_LBP = train_test_split(X_LBP, y_encoded, test_size=1/5, random_state=42, stratify=y_encoded)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_LBP = scaler.fit_transform(X_train_LBP)\n",
        "X_test_LBP = scaler.transform(X_test_LBP)\n",
        "\n",
        "print(f\"Dataset size: {df_LBP.shape}\")\n",
        "print(f\"Training size: {X_train_LBP.shape}, Testing size: {X_test_LBP.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awUGb0PmJK8S"
      },
      "source": [
        "# Applying PCA for dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Lcv0-yj-oC7e"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIP-Die8Zw1I"
      },
      "source": [
        "# PCA on CNN features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Sj5t1lrSJ3AL",
        "outputId": "315333af-93bc-4291-c8cb-6f10daed0dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3459, 300)\n",
            "(865, 300)\n"
          ]
        }
      ],
      "source": [
        "pca=PCA(n_components=300)\n",
        "\n",
        "X_train_cnn_pca=pca.fit_transform(X_train_cnn)\n",
        "X_test_cnn_pca=pca.transform(X_test_cnn)\n",
        "\n",
        "print(X_train_cnn_pca.shape)\n",
        "print(X_test_cnn_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV3iXQw4Zzxm"
      },
      "source": [
        "# PCA on HoG features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "84PdM4jfji_z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3459, 1000)\n",
            "(865, 1000)\n"
          ]
        }
      ],
      "source": [
        "pca=PCA(n_components=1000)\n",
        "\n",
        "X_train_hog_pca=pca.fit_transform(X_train_hog)\n",
        "X_test_hog_pca=pca.transform(X_test_hog)\n",
        "\n",
        "print(X_train_hog_pca.shape)\n",
        "print(X_test_hog_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmJHV_bkjp40"
      },
      "source": [
        "# PCA on LBP features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdySM0Z1jsyS",
        "outputId": "d91da2ec-400a-40f3-a791-56eed48bc6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3459, 50)\n",
            "(865, 50)\n"
          ]
        }
      ],
      "source": [
        "pca=PCA(n_components=50)\n",
        "\n",
        "X_train_LBP_pca=pca.fit_transform(X_train_LBP)\n",
        "X_test_LBP_pca=pca.transform(X_test_LBP)\n",
        "\n",
        "print(X_train_LBP_pca.shape)\n",
        "print(X_test_LBP_pca.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO_MKFsQGpPx"
      },
      "source": [
        "# Combining all features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_hog_pca = X_train_hog_pca[:, :50]  # Truncate to match CNN PCA\n",
        "X_train_cnn_pca = X_train_LBP_pca[:, :50]  # Truncate to match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_hog_pca = X_test_hog_pca[:, :50]  # Truncate to match CNN PCA\n",
        "X_test_cnn_pca = X_test_LBP_pca[:, :50]  # Truncate to match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dPU4c3XwkdPj"
      },
      "outputs": [],
      "source": [
        "combined_X_train = np.concatenate((X_train_cnn_pca, X_train_hog_pca, X_train_LBP_pca), axis=1)\n",
        "combined_X_test = np.concatenate((X_test_cnn_pca, X_test_hog_pca, X_test_LBP_pca), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELhA7ealldlc",
        "outputId": "945027e4-0fba-4f66-96a4-ee8e9d07a965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 36 134 146   6  41  23  61  28 134  53]\n",
            "[ 91  60 128  35  11 103  50 111  89  80]\n"
          ]
        }
      ],
      "source": [
        "y_train = y_train_cnn\n",
        "y_test = y_test_cnn\n",
        "\n",
        "print(y_train[:10])\n",
        "print(y_test[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3459, 150)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPWmL6HUo2Yf"
      },
      "source": [
        "# Check Printing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qRJ9QQpZRwcY"
      },
      "outputs": [],
      "source": [
        "# for i in range(X_test_cnn_pca.shape[0]):\n",
        "#   if i%100==0:\n",
        "#     print(X_test_cnn_pca[i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5x6rv8hSB16",
        "outputId": "fc3019cf-b4c6-4eee-c1f4-892597b3b799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Laura_Bush\n",
            "Angelina_Jolie\n",
            "Andre_Agassi\n",
            "Mike_Weir\n",
            "Colin_Powell\n",
            "John_Negroponte\n",
            "Dick_Cheney\n",
            "Vladimir_Putin\n",
            "Gerhard_Schroeder\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(y_test)):\n",
        "  if i%100==0:\n",
        "    print(label_encoder.inverse_transform([y_test[i]])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vd_jfouKV5K"
      },
      "source": [
        "# KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pNanG4XBJx-q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2sYnoEgFKlA5"
      },
      "outputs": [],
      "source": [
        "def euclidean_dist(x,y):\n",
        "  # x1,y1,z1=x\n",
        "  # x2,y2,z2=y\n",
        "  return math.sqrt(sum([(a-b)**2 for a,b in zip(x,y)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nbnWdaMJpOS",
        "outputId": "e09dae1a-7bb4-4d28-ac34-2bf956b1a9e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3166247903554\n"
          ]
        }
      ],
      "source": [
        "point1 = [2,3,4]\n",
        "point2 = [1,2,1]\n",
        "print(euclidean_dist(point1, point2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "VEjvfGrnm9vM"
      },
      "outputs": [],
      "source": [
        "k=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "MPcW1M_GOpjH"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBOh51aIlv0Q",
        "outputId": "c937d47f-6599-4fba-fa3c-932dc93fb620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label 0 detected\n",
            "Label 100 detected\n",
            "Label 200 detected\n",
            "Label 300 detected\n",
            "Label 400 detected\n",
            "Label 500 detected\n",
            "Label 600 detected\n",
            "Label 700 detected\n",
            "Label 800 detected\n",
            "['Juan_Carlos_Ferrero', 'Alejandro_Toledo', 'Muhammad_Ali', 'David_Beckham', 'Igor_Ivanov', 'Donald_Rumsfeld', 'Joschka_Fischer', 'George_W_Bush', 'Colin_Powell', 'Harrison_Ford', 'Nicanor_Duarte_Frutos', 'Roh_Moo-hyun', 'Jose_Maria_Aznar', 'Andre_Agassi', 'George_W_Bush', 'Norah_Jones', 'Donald_Rumsfeld', 'George_W_Bush', 'John_Ashcroft', 'David_Beckham', 'Gerhard_Schroeder', 'Renee_Zellweger', 'Tommy_Thompson', 'Donald_Rumsfeld', 'Sergey_Lavrov', 'Saddam_Hussein', 'George_W_Bush', 'Alvaro_Uribe', 'Abdullah_Gul', 'Lucio_Gutierrez', 'David_Beckham', 'Lleyton_Hewitt', 'Jennifer_Capriati', 'Trent_Lott', 'Adrien_Brody', 'Jeb_Bush', 'Colin_Powell', 'Colin_Powell', 'Donald_Rumsfeld', 'Alejandro_Toledo', 'Hillary_Clinton', 'George_W_Bush', 'George_HW_Bush', 'Jose_Maria_Aznar', 'George_W_Bush', 'George_W_Bush', 'Guillermo_Coria', 'Julianne_Moore', 'Norah_Jones', 'Roger_Federer', 'Gerhard_Schroeder', 'Atal_Bihari_Vajpayee', 'Tony_Blair', 'Alvaro_Uribe', 'George_W_Bush', 'George_W_Bush', 'Anna_Kournikova', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'George_W_Bush', 'Hillary_Clinton', 'Lance_Armstrong', 'Ricardo_Lagos', 'Bill_Simon', 'Dominique_de_Villepin', 'George_W_Bush', 'Amelie_Mauresmo', 'Colin_Powell', 'Roh_Moo-hyun', 'George_Robertson', 'Paul_Bremer', 'George_W_Bush', 'George_W_Bush', 'Saddam_Hussein', 'Colin_Powell', 'Tom_Ridge', 'Renee_Zellweger', 'Winona_Ryder', 'Donald_Rumsfeld', 'Andre_Agassi', 'David_Nalbandian', 'Richard_Gere', 'Edmund_Stoiber', 'Amelie_Mauresmo', 'Tony_Blair', 'Norah_Jones', 'George_W_Bush', 'Mahmoud_Abbas', 'Ariel_Sharon', 'Lance_Armstrong', 'Juan_Carlos_Ferrero', 'Mahmoud_Abbas', 'Bill_Clinton', 'Bill_Simon', 'Naomi_Watts', 'Halle_Berry', 'John_Snow', 'Mahathir_Mohamad', 'Jeb_Bush', 'George_W_Bush', 'Angelina_Jolie', 'Mike_Weir', 'Jiang_Zemin', 'George_W_Bush', 'Dominique_de_Villepin', 'Tony_Blair', 'George_W_Bush', 'Hugo_Chavez', 'Winona_Ryder', 'George_W_Bush', 'Dick_Cheney', 'Julianne_Moore', 'George_W_Bush', 'George_W_Bush', 'Britney_Spears', 'Tony_Blair', 'Nicole_Kidman', 'Hamid_Karzai', 'Amelie_Mauresmo', 'George_W_Bush', 'Venus_Williams', 'Ann_Veneman', 'Tommy_Thompson', 'Venus_Williams', 'Carlos_Moya', 'Carlos_Menem', 'Lance_Armstrong', 'Jacques_Rogge', 'Donald_Rumsfeld', 'Igor_Ivanov', 'George_HW_Bush', 'Saddam_Hussein', 'Rudolph_Giuliani', 'Alejandro_Toledo', 'Spencer_Abraham', 'Juan_Carlos_Ferrero', 'Gray_Davis', 'Jacques_Rogge', 'Anna_Kournikova', 'Jennifer_Lopez', 'Mahmoud_Abbas', 'Salma_Hayek', 'Naomi_Watts', 'Muhammad_Ali', 'Colin_Powell', 'Colin_Powell', 'Dominique_de_Villepin', 'Fidel_Castro', 'Donald_Rumsfeld', 'Alejandro_Toledo', 'Colin_Powell', 'Gerhard_Schroeder', 'Jennifer_Lopez', 'Tony_Blair', 'Gordon_Brown', 'Roh_Moo-hyun', 'Junichiro_Koizumi', 'Naomi_Watts', 'Colin_Powell', 'Tom_Ridge', 'John_Negroponte', 'Jennifer_Aniston', 'Salma_Hayek', 'Winona_Ryder', 'George_W_Bush', 'Gloria_Macapagal_Arroyo', 'George_W_Bush', 'Lleyton_Hewitt', 'Bill_Gates', 'George_W_Bush', 'Gordon_Brown', 'Joschka_Fischer', 'Tony_Blair', 'Venus_Williams', 'Colin_Powell', 'Megawati_Sukarnoputri', 'George_W_Bush', 'Jean_Chretien', 'Jean_Chretien', 'Carlos_Menem', 'Nestor_Kirchner', 'George_Robertson', 'George_W_Bush', 'Spencer_Abraham', 'John_Bolton', 'Joe_Lieberman', 'Colin_Powell', 'Gerhard_Schroeder', 'Pete_Sampras', 'Alvaro_Uribe', 'Megawati_Sukarnoputri', 'George_W_Bush', 'Kim_Clijsters', 'Spencer_Abraham', 'Harrison_Ford', 'Luiz_Inacio_Lula_da_Silva', 'Paul_Burrell', 'Tom_Ridge', 'Amelie_Mauresmo', 'Donald_Rumsfeld', 'George_Robertson', 'George_W_Bush', 'Ricardo_Lagos', 'Junichiro_Koizumi', 'Gerhard_Schroeder', 'Luiz_Inacio_Lula_da_Silva', 'Arnold_Schwarzenegger', 'Paul_Bremer', 'Bill_McBride', 'Megawati_Sukarnoputri', 'George_W_Bush', 'Ariel_Sharon', 'Gray_Davis', 'George_W_Bush', 'Bill_Gates', 'Norah_Jones', 'George_W_Bush', 'George_W_Bush', 'Roh_Moo-hyun', 'Tony_Blair', 'Tony_Blair', 'George_W_Bush', 'John_Ashcroft', 'Nestor_Kirchner', 'Fidel_Castro', 'Amelie_Mauresmo', 'Angelina_Jolie', 'Atal_Bihari_Vajpayee', 'Carlos_Menem', 'Paul_Wolfowitz', 'Gloria_Macapagal_Arroyo', 'Gloria_Macapagal_Arroyo', 'Atal_Bihari_Vajpayee', 'Megawati_Sukarnoputri', 'Muhammad_Ali', 'Alejandro_Toledo', 'Nestor_Kirchner', 'Pierce_Brosnan', 'Joschka_Fischer', 'Tom_Ridge', 'Jean_Charest', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'Lucio_Gutierrez', 'Saddam_Hussein', 'Jiang_Zemin', 'Serena_Williams', 'George_W_Bush', 'Ariel_Sharon', 'Jeremy_Greenstock', 'Javier_Solana', 'Luiz_Inacio_Lula_da_Silva', 'John_Ashcroft', 'Jeremy_Greenstock', 'Mahmoud_Abbas', 'George_HW_Bush', 'Tony_Blair', 'Michael_Bloomberg', 'George_W_Bush', 'Ariel_Sharon', 'Luiz_Inacio_Lula_da_Silva', 'Lindsay_Davenport', 'Mahmoud_Abbas', 'Junichiro_Koizumi', 'Colin_Powell', 'Jacques_Rogge', 'Anna_Kournikova', 'Jennifer_Capriati', 'Nicole_Kidman', 'George_W_Bush', 'George_W_Bush', 'George_W_Bush', 'Vladimir_Putin', 'Gerhard_Schroeder', 'Pete_Sampras', 'George_W_Bush', 'Roh_Moo-hyun', 'Saddam_Hussein', 'Alvaro_Uribe', 'Bill_Clinton', 'Adrien_Brody', 'Gordon_Brown', 'Colin_Powell', 'Saddam_Hussein', 'Igor_Ivanov', 'Halle_Berry', 'Colin_Powell', 'Howard_Dean', 'John_Snow', 'Gerhard_Schroeder', 'Atal_Bihari_Vajpayee', 'George_W_Bush', 'Colin_Powell', 'George_W_Bush', 'Colin_Powell', 'Bill_Clinton', 'Andre_Agassi', 'Roh_Moo-hyun', 'Silvio_Berlusconi', 'Juan_Carlos_Ferrero', 'Amelie_Mauresmo', 'John_Snow', 'Vicente_Fox', 'Junichiro_Koizumi', 'Gerhard_Schroeder', 'Gray_Davis', 'George_W_Bush', 'George_W_Bush', 'Michael_Bloomberg', 'George_W_Bush', 'Meryl_Streep', 'Jean_Chretien', 'Abdullah_Gul', 'Wen_Jiabao', 'Donald_Rumsfeld', 'Tom_Ridge', 'Julie_Gerberding', 'George_Robertson', 'Jeremy_Greenstock', 'Donald_Rumsfeld', 'Tommy_Thompson', 'Sergey_Lavrov', 'Pete_Sampras', 'Joe_Lieberman', 'Donald_Rumsfeld', 'Mahmoud_Abbas', 'Rudolph_Giuliani', 'Kofi_Annan', 'Eduardo_Duhalde', 'Colin_Powell', 'Spencer_Abraham', 'Jackie_Chan', 'Gloria_Macapagal_Arroyo', 'Bill_McBride', 'Andre_Agassi', 'Colin_Powell', 'Colin_Powell', 'George_W_Bush', 'George_W_Bush', 'George_W_Bush', 'Saddam_Hussein', 'George_W_Bush', 'Colin_Powell', 'Serena_Williams', 'Tim_Henman', 'Recep_Tayyip_Erdogan', 'Megawati_Sukarnoputri', 'George_W_Bush', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'Colin_Powell', 'George_W_Bush', 'Tom_Daschle', 'John_Bolton', 'John_Bolton', 'Naomi_Watts', 'Colin_Powell', 'Tom_Ridge', 'Nicole_Kidman', 'George_W_Bush', 'Arnold_Schwarzenegger', 'Renee_Zellweger', 'Donald_Rumsfeld', 'Jiri_Novak', 'David_Beckham', 'Britney_Spears', 'Donald_Rumsfeld', 'Ariel_Sharon', 'Tony_Blair', 'Donald_Rumsfeld', 'Adrien_Brody', 'Carlos_Moya', 'Luiz_Inacio_Lula_da_Silva', 'Kim_Ryong-sung', 'David_Beckham', 'Jennifer_Capriati', 'John_Ashcroft', 'Donald_Rumsfeld', 'Sergio_Vieira_De_Mello', 'George_W_Bush', 'Tony_Blair', 'Alvaro_Uribe', 'Angelina_Jolie', 'Renee_Zellweger', 'Roh_Moo-hyun', 'John_Bolton', 'Colin_Powell', 'Jennifer_Aniston', 'Laura_Bush', 'George_W_Bush', 'Lleyton_Hewitt', 'James_Blake', 'Meryl_Streep', 'Donald_Rumsfeld', 'Serena_Williams', 'George_W_Bush', 'Junichiro_Koizumi', 'Nicole_Kidman', 'Gerhard_Schroeder', 'Vladimir_Putin', 'Colin_Powell', 'Alejandro_Toledo', 'Serena_Williams', 'Jennifer_Aniston', 'Sergey_Lavrov', 'Jack_Straw', 'Megawati_Sukarnoputri', 'John_Howard', 'Sergey_Lavrov', 'Gerhard_Schroeder', 'Tony_Blair', 'Colin_Powell', 'Megawati_Sukarnoputri', 'Jeremy_Greenstock', 'Bill_Clinton', 'Lucio_Gutierrez', 'Gray_Davis', 'Lindsay_Davenport', 'Bill_Gates', 'Jeremy_Greenstock', 'Ari_Fleischer', 'George_W_Bush', 'Ricardo_Lagos', 'Colin_Powell', 'Julie_Gerberding', 'Jean_Chretien', 'Andre_Agassi', 'George_W_Bush', 'Salma_Hayek', 'Harrison_Ford', 'Julie_Gerberding', 'Pierce_Brosnan', 'George_W_Bush', 'Gordon_Brown', 'Richard_Gephardt', 'Tom_Daschle', 'Colin_Powell', 'Tony_Blair', 'Bill_Clinton', 'Adrien_Brody', 'Andre_Agassi', 'Nestor_Kirchner', 'George_W_Bush', 'Alvaro_Uribe', 'Queen_Elizabeth_II', 'Tony_Blair', 'Jack_Straw', 'Bill_Gates', 'Bill_Gates', 'Jean_Chretien', 'Andre_Agassi', 'Hu_Jintao', 'Mahmoud_Abbas', 'George_W_Bush', 'Donald_Rumsfeld', 'Abdullah_Gul', 'Arnold_Schwarzenegger', 'George_W_Bush', 'Tiger_Woods', 'Luiz_Inacio_Lula_da_Silva', 'Spencer_Abraham', 'Jennifer_Lopez', 'George_W_Bush', 'Jeb_Bush', 'Catherine_Zeta-Jones', 'Tony_Blair', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'Roh_Moo-hyun', 'George_W_Bush', 'Queen_Elizabeth_II', 'George_W_Bush', 'Dick_Cheney', 'John_Allen_Muhammad', 'Mark_Philippoussis', 'Tony_Blair', 'Juan_Carlos_Ferrero', 'George_W_Bush', 'Silvio_Berlusconi', 'John_Howard', 'John_Ashcroft', 'Catherine_Zeta-Jones', 'David_Beckham', 'George_W_Bush', 'Jean_Chretien', 'Richard_Gephardt', 'Atal_Bihari_Vajpayee', 'John_Allen_Muhammad', 'Tom_Cruise', 'Nicanor_Duarte_Frutos', 'Colin_Powell', 'Donald_Rumsfeld', 'Megawati_Sukarnoputri', 'John_Bolton', 'Jean_Chretien', 'Richard_Myers', 'Hu_Jintao', 'Kofi_Annan', 'Hu_Jintao', 'Guillermo_Coria', 'Colin_Powell', 'Nicole_Kidman', 'George_W_Bush', 'Nestor_Kirchner', 'Nicole_Kidman', 'Tommy_Thompson', 'George_Robertson', 'Norah_Jones', 'John_Kerry', 'Tiger_Woods', 'Jacques_Chirac', 'Lance_Armstrong', 'George_W_Bush', 'Alejandro_Toledo', 'George_W_Bush', 'Donald_Rumsfeld', 'Michael_Bloomberg', 'Luiz_Inacio_Lula_da_Silva', 'Ricardo_Lagos', 'Gerhard_Schroeder', 'Colin_Powell', 'Junichiro_Koizumi', 'Bill_Simon', 'Hamid_Karzai', 'Naomi_Watts', 'Juan_Carlos_Ferrero', 'Nestor_Kirchner', 'John_Ashcroft', 'Norah_Jones', 'Naomi_Watts', 'Rudolph_Giuliani', 'Lucio_Gutierrez', 'David_Nalbandian', 'Alvaro_Uribe', 'Jean_Charest', 'George_W_Bush', 'Dick_Cheney', 'Bill_Simon', 'Mahmoud_Abbas', 'Mahathir_Mohamad', 'George_W_Bush', 'Angelina_Jolie', 'Tony_Blair', 'George_W_Bush', 'Hugo_Chavez', 'Lleyton_Hewitt', 'Juan_Carlos_Ferrero', 'Tony_Blair', 'Nicole_Kidman', 'George_W_Bush', 'George_W_Bush', 'Jennifer_Aniston', 'Abdullah_Gul', 'Colin_Powell', 'Colin_Powell', 'Gerhard_Schroeder', 'Kofi_Annan', 'Sergey_Lavrov', 'John_Snow', 'Jack_Straw', 'Alejandro_Toledo', 'George_W_Bush', 'David_Beckham', 'Carlos_Menem', 'George_W_Bush', 'Jiri_Novak', 'George_W_Bush', 'Ricardo_Lagos', 'Catherine_Zeta-Jones', 'Taha_Yassin_Ramadan', 'George_W_Bush', 'Jean_Charest', 'Hu_Jintao', 'Tom_Ridge', 'Eduardo_Duhalde', 'Igor_Ivanov', 'Jean_Chretien', 'Joschka_Fischer', 'Ricardo_Lagos', 'Wen_Jiabao', 'Hu_Jintao', 'Tom_Ridge', 'George_W_Bush', 'Donald_Rumsfeld', 'George_W_Bush', 'Jacques_Chirac', 'David_Beckham', 'Gerhard_Schroeder', 'Colin_Powell', 'Abdullah_Gul', 'James_Kelly', 'George_W_Bush', 'Anna_Kournikova', 'George_W_Bush', 'Nestor_Kirchner', 'George_W_Bush', 'Jiri_Novak', 'Taha_Yassin_Ramadan', 'George_W_Bush', 'George_W_Bush', 'Igor_Ivanov', 'Juan_Carlos_Ferrero', 'Donald_Rumsfeld', 'Nicole_Kidman', 'Richard_Gephardt', 'Hu_Jintao', 'Bill_McBride', 'Rudolph_Giuliani', 'Roger_Federer', 'James_Kelly', 'Kofi_Annan', 'Colin_Powell', 'Harrison_Ford', 'Ann_Veneman', 'Guillermo_Coria', 'Salma_Hayek', 'Jean_Chretien', 'Donald_Rumsfeld', 'Taha_Yassin_Ramadan', 'Laura_Bush', 'Colin_Powell', 'Arnold_Schwarzenegger', 'Michael_Jackson', 'Pete_Sampras', 'George_W_Bush', 'Michael_Bloomberg', 'Meryl_Streep', 'Jean_Chretien', 'Junichiro_Koizumi', 'Alejandro_Toledo', 'Colin_Powell', 'Paradorn_Srichaphan', 'Jeremy_Greenstock', 'Kofi_Annan', 'Mahmoud_Abbas', 'John_Snow', 'Arnold_Schwarzenegger', 'Kofi_Annan', 'Jeb_Bush', 'Donald_Rumsfeld', 'Tony_Blair', 'George_W_Bush', 'George_W_Bush', 'Laura_Bush', 'Gerhard_Schroeder', 'Jean_Charest', 'Juan_Carlos_Ferrero', 'Hugo_Chavez', 'Tony_Blair', 'George_W_Bush', 'Bill_Simon', 'Gordon_Brown', 'George_W_Bush', 'Jeremy_Greenstock', 'Halle_Berry', 'Nancy_Pelosi', 'Nicole_Kidman', 'Mahmoud_Abbas', 'Hans_Blix', 'Recep_Tayyip_Erdogan', 'George_W_Bush', 'Jiri_Novak', 'Abdullah_Gul', 'Megawati_Sukarnoputri', 'David_Beckham', 'Silvio_Berlusconi', 'Paul_Bremer', 'Nancy_Pelosi', 'Recep_Tayyip_Erdogan', 'Colin_Powell', 'Jennifer_Lopez', 'Winona_Ryder', 'Donald_Rumsfeld', 'John_Ashcroft', 'Hu_Jintao', 'Gerhard_Schroeder', 'Jean_Chretien', 'Catherine_Zeta-Jones', 'Winona_Ryder', 'Luiz_Inacio_Lula_da_Silva', 'Jacques_Chirac', 'Serena_Williams', 'Tony_Blair', 'George_W_Bush', 'Jeb_Bush', 'Tom_Cruise', 'Donald_Rumsfeld', 'George_W_Bush', 'Bill_Gates', 'Junichiro_Koizumi', 'Jennifer_Capriati', 'Adrien_Brody', 'Pete_Sampras', 'Adrien_Brody', 'Jacques_Chirac', 'George_W_Bush', 'Colin_Powell', 'George_W_Bush', 'John_Negroponte', 'Lleyton_Hewitt', 'George_W_Bush', 'Donald_Rumsfeld', 'Andre_Agassi', 'Hugo_Chavez', 'George_W_Bush', 'Ariel_Sharon', 'George_W_Bush', 'Colin_Powell', 'Silvio_Berlusconi', 'Mark_Philippoussis', 'Colin_Powell', 'Laura_Bush', 'Alejandro_Toledo', 'Junichiro_Koizumi', 'Colin_Powell', 'Jean_Charest', 'Jennifer_Lopez', 'Tommy_Franks', 'John_Snow', 'Jeremy_Greenstock', 'Pete_Sampras', 'Silvio_Berlusconi', 'Colin_Powell', 'George_W_Bush', 'Nicole_Kidman', 'Luiz_Inacio_Lula_da_Silva', 'Ariel_Sharon', 'Tommy_Franks', 'Ann_Veneman', 'Jeb_Bush', 'Gordon_Brown', 'Michael_Schumacher', 'Spencer_Abraham', 'Jean_Chretien', 'Alejandro_Toledo', 'James_Blake', 'Jason_Kidd', 'Venus_Williams', 'Salma_Hayek', 'George_Robertson', 'Jennifer_Lopez', 'Lleyton_Hewitt', 'Pierce_Brosnan', 'Jeb_Bush', 'George_W_Bush', 'John_Bolton', 'Gonzalo_Sanchez_de_Lozada', 'Gerhard_Schroeder', 'Alvaro_Uribe', 'Andre_Agassi', 'Nestor_Kirchner', 'Ariel_Sharon', 'Tony_Blair', 'Juan_Carlos_Ferrero', 'Jeb_Bush', 'Jennifer_Lopez', 'Colin_Powell', 'Jean_Chretien', 'Pierce_Brosnan', 'John_Kerry', 'George_W_Bush', 'Kofi_Annan', 'Spencer_Abraham', 'Eduardo_Duhalde', 'George_W_Bush', 'Colin_Powell', 'David_Beckham', 'Gerhard_Schroeder', 'Muhammad_Ali', 'Igor_Ivanov', 'George_W_Bush', 'Lleyton_Hewitt', 'Alejandro_Toledo', 'Jeb_Bush', 'John_Negroponte', 'Laura_Bush', 'Andy_Roddick', 'Nicole_Kidman', 'Donald_Rumsfeld', 'John_Negroponte', 'Bill_Clinton', 'Tom_Daschle', 'Queen_Elizabeth_II', 'George_W_Bush', 'Gray_Davis', 'Igor_Ivanov', 'Junichiro_Koizumi', 'Carlos_Menem', 'Bill_Clinton', 'George_W_Bush', 'Donald_Rumsfeld', 'Richard_Myers', 'Donald_Rumsfeld', 'Michael_Jackson', 'Paul_Bremer', 'Colin_Powell', 'George_W_Bush', 'George_W_Bush', 'Nicole_Kidman', 'George_W_Bush', 'Halle_Berry', 'Fidel_Castro', 'George_W_Bush', 'Jiang_Zemin', 'John_Negroponte', 'Tony_Blair', 'Jennifer_Capriati', 'Tony_Blair', 'Colin_Powell', 'George_Robertson', 'Juan_Carlos_Ferrero', 'Tony_Blair', 'Pierce_Brosnan', 'Jennifer_Lopez', 'Colin_Powell', 'Bill_Simon', 'Ricardo_Lagos', 'Tony_Blair', 'Julie_Gerberding', 'Gerhard_Schroeder', 'Jean_Chretien', 'Alejandro_Toledo', 'George_W_Bush', 'Winona_Ryder', 'Jennifer_Garner', 'George_W_Bush', 'George_W_Bush', 'Jean_Chretien', 'George_W_Bush', 'David_Nalbandian', 'Bill_Clinton', 'George_W_Bush', 'Hugo_Chavez', 'Nestor_Kirchner', 'Jack_Straw', 'Bill_Simon', 'George_W_Bush', 'Luiz_Inacio_Lula_da_Silva', 'Carlos_Moya', 'Bill_Clinton', 'Gerhard_Schroeder', 'Ricardo_Lagos', 'Rudolph_Giuliani', 'George_W_Bush', 'Bill_McBride', 'Guillermo_Coria', 'Junichiro_Koizumi', 'Donald_Rumsfeld', 'Ricardo_Lagos', 'Tony_Blair', 'Tom_Daschle', 'Gerhard_Schroeder', 'George_W_Bush', 'Mahmoud_Abbas', 'Jennifer_Capriati', 'Donald_Rumsfeld', 'Jennifer_Lopez', 'Ariel_Sharon', 'David_Nalbandian', 'Tommy_Thompson', 'Igor_Ivanov', 'Colin_Powell', 'Rubens_Barrichello', 'Wen_Jiabao', 'Nestor_Kirchner']\n"
          ]
        }
      ],
      "source": [
        "predictions=[]\n",
        "for i in range(combined_X_test.shape[0]):\n",
        "  distances=[]\n",
        "  nearest_labels=[]\n",
        "  for j in range(combined_X_train.shape[0]):\n",
        "    # append the pair (distance, index) to distances\n",
        "    dist=euclidean_dist(combined_X_test[i], combined_X_train[j])\n",
        "    distances.append((dist, j))\n",
        "  # sorting distances on the basis of first item of pair i.e. distance\n",
        "  distances.sort(key=lambda x:x[0])\n",
        "  for k1 in range(min(k, len(distances))):  # Ensure k does not exceed available distances\n",
        "    nearest_labels.append(y_train[distances[k1][1]])\n",
        "\n",
        "  label_counts = Counter(nearest_labels)\n",
        "  most_common_label = label_counts.most_common(1)[0][0] if nearest_labels else -1\n",
        "\n",
        "  predictions.append(label_encoder.inverse_transform([most_common_label])[0])\n",
        "\n",
        "  if i%100==0:\n",
        "    print(f'Label {i} detected')\n",
        "    # if most_common_label!=-1:\n",
        "    #   print(X_test_cnn_pca[i], '\\t', label_encoder.inverse_transform([most_common_label])[0])\n",
        "    # else:\n",
        "    #   print(X_test_cnn_pca[i], '\\t', 'Unknown')\n",
        "\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOPR3lO85TGofGnejXG7e1W",
      "collapsed_sections": [
        "svIt5l3bdrY_"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
