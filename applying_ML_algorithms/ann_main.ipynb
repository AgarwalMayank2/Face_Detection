{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "66e2be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import spliter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "685b9e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.266585</td>\n",
       "      <td>1.337187</td>\n",
       "      <td>1.352905</td>\n",
       "      <td>0.100848</td>\n",
       "      <td>1.880685</td>\n",
       "      <td>0.059888</td>\n",
       "      <td>2.773605</td>\n",
       "      <td>0.115643</td>\n",
       "      <td>0.138749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.733759</td>\n",
       "      <td>1.643910</td>\n",
       "      <td>0.041306</td>\n",
       "      <td>1.488236</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>0.247783</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.355948</td>\n",
       "      <td>0.750634</td>\n",
       "      <td>0.909794</td>\n",
       "      <td>0.188214</td>\n",
       "      <td>0.680066</td>\n",
       "      <td>0.221442</td>\n",
       "      <td>3.089571</td>\n",
       "      <td>0.342022</td>\n",
       "      <td>0.087186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093867</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.859610</td>\n",
       "      <td>1.764073</td>\n",
       "      <td>0.250430</td>\n",
       "      <td>1.133540</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.153542</td>\n",
       "      <td>0.236034</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.267111</td>\n",
       "      <td>1.015316</td>\n",
       "      <td>1.154480</td>\n",
       "      <td>0.131544</td>\n",
       "      <td>1.066389</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>3.701925</td>\n",
       "      <td>0.145037</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080086</td>\n",
       "      <td>0.089589</td>\n",
       "      <td>0.663708</td>\n",
       "      <td>1.854499</td>\n",
       "      <td>0.078751</td>\n",
       "      <td>1.240009</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.105058</td>\n",
       "      <td>0.227633</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.260295</td>\n",
       "      <td>0.882900</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>0.106698</td>\n",
       "      <td>2.663052</td>\n",
       "      <td>0.057836</td>\n",
       "      <td>1.854394</td>\n",
       "      <td>0.209269</td>\n",
       "      <td>0.103750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181255</td>\n",
       "      <td>0.182038</td>\n",
       "      <td>0.397535</td>\n",
       "      <td>1.222931</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.878194</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>0.110492</td>\n",
       "      <td>0.129523</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.347203</td>\n",
       "      <td>0.623839</td>\n",
       "      <td>0.817085</td>\n",
       "      <td>0.212599</td>\n",
       "      <td>1.026321</td>\n",
       "      <td>0.176634</td>\n",
       "      <td>2.486715</td>\n",
       "      <td>0.426571</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267895</td>\n",
       "      <td>0.136346</td>\n",
       "      <td>0.713298</td>\n",
       "      <td>0.978184</td>\n",
       "      <td>0.059828</td>\n",
       "      <td>1.008205</td>\n",
       "      <td>0.042905</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>0.199120</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2050 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0  0.266585  1.337187  1.352905  0.100848  1.880685  0.059888   \n",
       "1           1  0.355948  0.750634  0.909794  0.188214  0.680066  0.221442   \n",
       "2           2  0.267111  1.015316  1.154480  0.131544  1.066389  0.024949   \n",
       "3           3  0.260295  0.882900  0.885955  0.106698  2.663052  0.057836   \n",
       "4           4  0.347203  0.623839  0.817085  0.212599  1.026321  0.176634   \n",
       "\n",
       "          6         7         8  ...      2039      2040      2041      2042  \\\n",
       "0  2.773605  0.115643  0.138749  ...  0.039434  0.071662  0.733759  1.643910   \n",
       "1  3.089571  0.342022  0.087186  ...  0.093867  0.089694  0.859610  1.764073   \n",
       "2  3.701925  0.145037  0.082419  ...  0.080086  0.089589  0.663708  1.854499   \n",
       "3  1.854394  0.209269  0.103750  ...  0.181255  0.182038  0.397535  1.222931   \n",
       "4  2.486715  0.426571  0.345026  ...  0.267895  0.136346  0.713298  0.978184   \n",
       "\n",
       "       2043      2044      2045      2046      2047         2048  \n",
       "0  0.041306  1.488236  0.048181  0.247783  0.300232  Paul_Bremer  \n",
       "1  0.250430  1.133540  0.004091  0.153542  0.236034  Paul_Bremer  \n",
       "2  0.078751  1.240009  0.065222  0.105058  0.227633  Paul_Bremer  \n",
       "3  0.007285  0.878194  0.016247  0.110492  0.129523  Paul_Bremer  \n",
       "4  0.059828  1.008205  0.042905  0.028597  0.199120  Paul_Bremer  \n",
       "\n",
       "[5 rows x 2050 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('utils/filtered_CNN_features_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d929c0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266585</td>\n",
       "      <td>1.337187</td>\n",
       "      <td>1.352905</td>\n",
       "      <td>0.100848</td>\n",
       "      <td>1.880685</td>\n",
       "      <td>0.059888</td>\n",
       "      <td>2.773605</td>\n",
       "      <td>0.115643</td>\n",
       "      <td>0.138749</td>\n",
       "      <td>0.056121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0.071662</td>\n",
       "      <td>0.733759</td>\n",
       "      <td>1.643910</td>\n",
       "      <td>0.041306</td>\n",
       "      <td>1.488236</td>\n",
       "      <td>0.048181</td>\n",
       "      <td>0.247783</td>\n",
       "      <td>0.300232</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.355948</td>\n",
       "      <td>0.750634</td>\n",
       "      <td>0.909794</td>\n",
       "      <td>0.188214</td>\n",
       "      <td>0.680066</td>\n",
       "      <td>0.221442</td>\n",
       "      <td>3.089571</td>\n",
       "      <td>0.342022</td>\n",
       "      <td>0.087186</td>\n",
       "      <td>0.234741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093867</td>\n",
       "      <td>0.089694</td>\n",
       "      <td>0.859610</td>\n",
       "      <td>1.764073</td>\n",
       "      <td>0.250430</td>\n",
       "      <td>1.133540</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.153542</td>\n",
       "      <td>0.236034</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267111</td>\n",
       "      <td>1.015316</td>\n",
       "      <td>1.154480</td>\n",
       "      <td>0.131544</td>\n",
       "      <td>1.066389</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>3.701925</td>\n",
       "      <td>0.145037</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>0.253356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080086</td>\n",
       "      <td>0.089589</td>\n",
       "      <td>0.663708</td>\n",
       "      <td>1.854499</td>\n",
       "      <td>0.078751</td>\n",
       "      <td>1.240009</td>\n",
       "      <td>0.065222</td>\n",
       "      <td>0.105058</td>\n",
       "      <td>0.227633</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.260295</td>\n",
       "      <td>0.882900</td>\n",
       "      <td>0.885955</td>\n",
       "      <td>0.106698</td>\n",
       "      <td>2.663052</td>\n",
       "      <td>0.057836</td>\n",
       "      <td>1.854394</td>\n",
       "      <td>0.209269</td>\n",
       "      <td>0.103750</td>\n",
       "      <td>0.149302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181255</td>\n",
       "      <td>0.182038</td>\n",
       "      <td>0.397535</td>\n",
       "      <td>1.222931</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>0.878194</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>0.110492</td>\n",
       "      <td>0.129523</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.347203</td>\n",
       "      <td>0.623839</td>\n",
       "      <td>0.817085</td>\n",
       "      <td>0.212599</td>\n",
       "      <td>1.026321</td>\n",
       "      <td>0.176634</td>\n",
       "      <td>2.486715</td>\n",
       "      <td>0.426571</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>0.375072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267895</td>\n",
       "      <td>0.136346</td>\n",
       "      <td>0.713298</td>\n",
       "      <td>0.978184</td>\n",
       "      <td>0.059828</td>\n",
       "      <td>1.008205</td>\n",
       "      <td>0.042905</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>0.199120</td>\n",
       "      <td>Paul_Bremer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.266585  1.337187  1.352905  0.100848  1.880685  0.059888  2.773605   \n",
       "1  0.355948  0.750634  0.909794  0.188214  0.680066  0.221442  3.089571   \n",
       "2  0.267111  1.015316  1.154480  0.131544  1.066389  0.024949  3.701925   \n",
       "3  0.260295  0.882900  0.885955  0.106698  2.663052  0.057836  1.854394   \n",
       "4  0.347203  0.623839  0.817085  0.212599  1.026321  0.176634  2.486715   \n",
       "\n",
       "          7         8         9  ...      2039      2040      2041      2042  \\\n",
       "0  0.115643  0.138749  0.056121  ...  0.039434  0.071662  0.733759  1.643910   \n",
       "1  0.342022  0.087186  0.234741  ...  0.093867  0.089694  0.859610  1.764073   \n",
       "2  0.145037  0.082419  0.253356  ...  0.080086  0.089589  0.663708  1.854499   \n",
       "3  0.209269  0.103750  0.149302  ...  0.181255  0.182038  0.397535  1.222931   \n",
       "4  0.426571  0.345026  0.375072  ...  0.267895  0.136346  0.713298  0.978184   \n",
       "\n",
       "       2043      2044      2045      2046      2047         2048  \n",
       "0  0.041306  1.488236  0.048181  0.247783  0.300232  Paul_Bremer  \n",
       "1  0.250430  1.133540  0.004091  0.153542  0.236034  Paul_Bremer  \n",
       "2  0.078751  1.240009  0.065222  0.105058  0.227633  Paul_Bremer  \n",
       "3  0.007285  0.878194  0.016247  0.110492  0.129523  Paul_Bremer  \n",
       "4  0.059828  1.008205  0.042905  0.028597  0.199120  Paul_Bremer  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d7cf309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4324, 2049)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a8f1c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['2048'] = label_encoder.fit_transform(data['2048'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "51329d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/all_work/ML-DL/Face_Identification/Face_Detection/applying_ML_algorithms/utils/spliter.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train = pd.concat([train, train_subset])\n",
      "/home/mayank/all_work/ML-DL/Face_Identification/Face_Detection/applying_ML_algorithms/utils/spliter.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test = pd.concat([test, test_subset])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3813, 2048), (511, 2048), (3813,), (511,))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = spliter.train_test_spliter(data, target_col='2048', train_size = 0.9)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ddc168be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3813, 158)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype(np.float32).reshape(-1, 1)\n",
    "y_test = y_test.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "onehothotencoder = OneHotEncoder()\n",
    "y_train = onehothotencoder.fit_transform(y_train).toarray()\n",
    "y_test = onehothotencoder.transform(y_test).toarray()\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "634664dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Part 1: Function Implementations\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)  # numerical stability\n",
    "    z = np.clip(z, -50, 50)  # limit extreme values\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return (z>0)*1\n",
    "\n",
    "def linear(z):\n",
    "    return z\n",
    "\n",
    "def linear_derivative(z):\n",
    "    return 1\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true-y_pred))\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    eps = 1e-15  # avoid log(0)\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "\n",
    "def activation_decider(activation, z):\n",
    "  if activation == 'sigmoid':\n",
    "    return sigmoid(z)\n",
    "  elif activation == 'relu':\n",
    "    return relu(z)\n",
    "  elif activation == 'linear':\n",
    "    return linear(z)\n",
    "  elif activation == 'softmax':\n",
    "    return softmax(z)\n",
    "\n",
    "def activation_derivative_decider(activation, z):\n",
    "  if activation == 'sigmoid':\n",
    "    return sigmoid_derivative(z)\n",
    "  elif activation == 'relu':\n",
    "    return relu_derivative(z)\n",
    "  elif activation == 'linear':\n",
    "    return linear_derivative(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7ad6cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, layers, activations):\n",
    "        self.layers = layers\n",
    "        self.activations = activations\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            # He initialization for ReLU, Glorot otherwise\n",
    "            if activations[i] == 'relu':\n",
    "                stddev = np.sqrt(2 / layers[i])  # He initialization\n",
    "            else:\n",
    "                stddev = np.sqrt(1 / (layers[i] + layers[i + 1]))  # Glorot/Xavier\n",
    "            self.weights.append(np.random.randn(layers[i], layers[i + 1]) * stddev)\n",
    "            self.biases.append(np.zeros((1, layers[i + 1])))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_values = []\n",
    "        activation_values = [x]\n",
    "\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(x, self.weights[i]) + self.biases[i]\n",
    "            z_values.append(z)\n",
    "            x = activation_decider(self.activations[i], z)\n",
    "            activation_values.append(x)\n",
    "\n",
    "        return z_values, activation_values\n",
    "\n",
    "    def backward(self, x, y, activations, z_values, learning_rate):\n",
    "        m = x.shape[0]\n",
    "        deltas = []\n",
    "\n",
    "        # Output layer delta\n",
    "        if self.activations[-1] == 'softmax':\n",
    "            delta = activations[-1] - y  # softmax + cross-entropy\n",
    "        else:\n",
    "            delta = (activations[-1] - y) * activation_derivative_decider(self.activations[-1], z_values[-1])\n",
    "\n",
    "        deltas.append(delta)\n",
    "\n",
    "        # Backpropagate through hidden layers\n",
    "        for i in reversed(range(len(self.weights) - 1)):\n",
    "            delta = deltas[-1].dot(self.weights[i + 1].T) * activation_derivative_decider(self.activations[i], z_values[i])\n",
    "            deltas.append(delta)\n",
    "\n",
    "        deltas.reverse()\n",
    "\n",
    "        # Update weights and biases\n",
    "        for i in range(len(self.weights)):\n",
    "            a_prev = x if i == 0 else activations[i]\n",
    "            grad_w = a_prev.T.dot(deltas[i]) / m\n",
    "            grad_b = np.mean(deltas[i], axis=0, keepdims=True)\n",
    "            grad_w = np.clip(grad_w, -1.0, 1.0)\n",
    "            grad_b = np.clip(grad_b, -1.0, 1.0)\n",
    "            self.weights[i] -= learning_rate * grad_w\n",
    "            self.biases[i] -= learning_rate * grad_b\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            z_values, activations = self.forward(x_train)\n",
    "            self.backward(x_train, y_train, activations, z_values, learning_rate)\n",
    "            if (epoch + 1)%100 == 0:\n",
    "                loss = cross_entropy_loss(y_train, activations[-1])\n",
    "                print(f\"Epoch {epoch+1}: Loss = {loss:.6f}\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        _, activations = self.forward(x)\n",
    "        return np.argmax(activations[-1], axis=1)  # class prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5936bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss = 1.613926\n",
      "Epoch 200: Loss = 0.818150\n",
      "Epoch 300: Loss = 0.104134\n",
      "Epoch 400: Loss = 0.046099\n",
      "Epoch 500: Loss = 0.027508\n",
      "Epoch 600: Loss = 0.019040\n",
      "Epoch 700: Loss = 0.014332\n",
      "Epoch 800: Loss = 0.011377\n",
      "Epoch 900: Loss = 0.009366\n",
      "Epoch 1000: Loss = 0.007919\n",
      "Train Accuracy : 1.0\n",
      "Test Accuracy : 0.44227005870841485\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train.shape[1]\n",
    "num_classes = len(data['2048'].unique())\n",
    "\n",
    "nn = NeuralNetwork([input_size, 512, 256, 128, num_classes], activations = ['relu', 'relu', 'relu', 'softmax'])\n",
    "nn.train(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "predictions = nn.predict(x_train)\n",
    "acc = np.mean(predictions == y_train.argmax(axis=1))\n",
    "print(f\"Train Accuracy : {acc}\")\n",
    "\n",
    "predictions = nn.predict(x_test)\n",
    "acc = np.mean(predictions == y_test.argmax(axis=1))\n",
    "print(f\"Test Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6584e334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048\n",
       "35     530\n",
       "23     236\n",
       "149    144\n",
       "29     121\n",
       "36     109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = data['2048'].value_counts()\n",
    "filter_labels = counts[counts > 80].index\n",
    "data = data[data['2048'].isin(filter_labels)]\n",
    "data['2048'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f0f9e6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/all_work/ML-DL/Face_Identification/Face_Detection/applying_ML_algorithms/utils/spliter.py:17: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train = pd.concat([train, train_subset])\n",
      "/home/mayank/all_work/ML-DL/Face_Identification/Face_Detection/applying_ML_algorithms/utils/spliter.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  test = pd.concat([test, test_subset])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1024, 2048), (116, 2048), (1024,), (116,))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = spliter.train_test_spliter(data, target_col='2048', train_size = 0.9)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7c38bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=4)\n",
    "lda.fit(x_train, y_train.astype(np.float32))\n",
    "x_train_lda = lda.transform(x_train)\n",
    "x_test_lda = lda.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "23435c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 5)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.astype(np.float32).reshape(-1, 1)\n",
    "y_test = y_test.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "onehothotencoder = OneHotEncoder()\n",
    "y_train = onehothotencoder.fit_transform(y_train).toarray()\n",
    "y_test = onehothotencoder.transform(y_test).toarray()\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x_train.shape[1]\n",
    "num_classes = len(data['2048'].unique())\n",
    "\n",
    "nn = NeuralNetwork([input_size, 512, 256, 128, num_classes], activations = ['relu', 'relu', 'relu', 'softmax'])\n",
    "nn.train(x_train, y_train, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "predictions = nn.predict(x_train)\n",
    "acc = np.mean(predictions == y_train.argmax(axis=1))\n",
    "print(f\"Train Accuracy : {acc}\")\n",
    "\n",
    "predictions = nn.predict(x_test)\n",
    "acc = np.mean(predictions == y_test.argmax(axis=1))\n",
    "print(f\"Test Accuracy : {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "50d03133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Loss = 0.073208\n",
      "Epoch 200: Loss = 0.038483\n",
      "Epoch 300: Loss = 0.027264\n",
      "Epoch 400: Loss = 0.021565\n",
      "Epoch 500: Loss = 0.018062\n",
      "Epoch 600: Loss = 0.015673\n",
      "Epoch 700: Loss = 0.013933\n",
      "Epoch 800: Loss = 0.012607\n",
      "Epoch 900: Loss = 0.011532\n",
      "Epoch 1000: Loss = 0.010638\n",
      "Epoch 1100: Loss = 0.009913\n",
      "Epoch 1200: Loss = 0.009323\n",
      "Epoch 1300: Loss = 0.008818\n",
      "Epoch 1400: Loss = 0.008380\n",
      "Epoch 1500: Loss = 0.007996\n",
      "Epoch 1600: Loss = 0.007656\n",
      "Epoch 1700: Loss = 0.007351\n",
      "Epoch 1800: Loss = 0.007076\n",
      "Epoch 1900: Loss = 0.006826\n",
      "Epoch 2000: Loss = 0.006598\n",
      "Train Accuracy : 0.9990234375\n",
      "Test Accuracy : 0.7672413793103449\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train_lda.shape[1]\n",
    "num_classes = len(data['2048'].unique())\n",
    "\n",
    "nn = NeuralNetwork([input_size, 32, 16, num_classes], activations = ['relu', 'relu', 'softmax'])\n",
    "nn.train(x_train_lda, y_train, epochs=2000, learning_rate=0.01)\n",
    "\n",
    "predictions = nn.predict(x_train_lda)\n",
    "acc = np.mean(predictions == y_train.argmax(axis=1))\n",
    "print(f\"Train Accuracy : {acc}\")\n",
    "\n",
    "predictions = nn.predict(x_test_lda)\n",
    "acc = np.mean(predictions == y_test.argmax(axis=1))\n",
    "print(f\"Test Accuracy : {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
