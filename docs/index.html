<!DOCTYPE html>
<html>
<head>
	<title>Face Detection Project</title>
	<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">

	<link rel="stylesheet" type="text/css" href="styles.css">
	<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
	<div style="position: absolute; right: 120px; top: 30px; z-index: 1;">
		<img src="images/IITJ COLOURED.png" alt="Institute Logo" style="height: 120px; margin-right: 45px;">
	</div>
	<div class="project-container">
		<h1>Face Identification</h1>
		<p style=" class ="subtitle";>PRML project 2025</p>
		<hr>
		<h2>Team Members</h2>
		<ul class="team-members">
			<li><a style="color:black" href="https://www.linkedin.com/in/debadatta-sahoo-078b1128a/" target="_blank">(B23CM1013) Debadatta Sahoo</a></li>
			<li><a style="color: black" href="https://www.linkedin.com/in/mayank-agarwal-2bb066281/" target="_blank">(B23CM1052) Mayank Agarwal</a></li>
			<li><a style="color: black" href="https://www.linkedin.com/in/dhruv-mishra-a3319b28b/" target="_blank">(B23CS1090) Dhruv Mishra</a></li>
			<li><a style="color: black" href="https://www.linkedin.com/in/shreekar1069/" target="_blank">(B23CS1069) Shreekar Mane</a></li>
			<li><a style="color: black" href="https://www.linkedin.com/in/tavishi-srivastava-16a4582a2/" target="_blank">(B23CS1101) Tavishi Srivastava</a></li>
			<li><a style="color: black" href="https://www.linkedin.com/in/ekta-saini-b8458128b/" target="_blank">(B23CS1018) Ekta Saini</a></li>
		</ul>
	</div>
    <div class="project-container">
        <h2>Project Details</h2>
		<a href="files/PRMLproj_report.pdf" target="_blank">Project Report</a> <br>
        <a href="https://github.com/AgarwalMayank2/Face_Detection" target="_blank">Github Repository</a> <br>
		<a href="" target="_blank">Short talk on youtube</a>
        <p>Face Identification is a computer technology being used in a variety of applications that identifies human faces in digital images. Face detection also refers to the psychological process by which humans locate and attend to faces in a visual scene. The project aims to detect faces in images using Basic classifier techniques. <br>
		In this project we will use some basic classifier techniques to identify faces in images. Our models are trained on <a><a href="https://www.kaggle.com/datasets/jessicali9530/lfw-dataset?select=peopleDevTrain.csv" target="_blank">LFW Dataset</a>. We will use the following algorithms to detect faces in images</p>
		</p>
	</div>
	<div class="project-container">
		<h2>Content</h2>
		<ul>
			<li><a href="#processing_data">Data processing</a></li>
			<li><a href="#knn">KNN algorithm</a></li>
			<li><a href="#nb">Naive Bayes algorithm</a></li>
			<li><a href="#dt">Decision Tree algorithm</a></li>
			<li><a href="#svm">Support Vector Machine algorithm</a></li>
		</ul>
	</div>
		<div class="project-container">
			<h2 id="processing_data">Data pre-processing</h2>
			<hr>
			<h3>About processed dataset</h3>
			<p>
				
				Data preprocessing is a crucial step in machine learning, especially in face identification tasks. The raw images in the LFW dataset come in various sizes, color schemes, and lighting conditions. To prepare these for model training, we applied several preprocessing techniques such as resizing, filtering, and normalization. <br>	
			</p>
			<hr>
			<h3>How we processed the data</h3>
			<p>
				<ul>
					<li>filtered data set to include images with count more than 10</li>
					<li>using pretrained Resnet to extract CNN features and saving into csv</li>
					<li>from skimage library we imported functions to extract HoG features and store into csv</li>
					<li>used openCV to extract LBP features and store into csv</li>
					<li>then we applied some more filtering and PCA/LDA for dimensionality reduction</li>
				</ul>
				This is how our final dataset was made and was then used to train on various algorithms mentioned below.
			</p>
			<hr>
			<h3>Why we processed the data</h3>
			<p>
				Preprocessing was essential for:
				<ul>
				<li>Reducing dimensionality and complexity of the input images.</li>

				<li>Improving model generalization by removing irrelevant variation in lighting or size.</li>
				
				<li>Achieving faster training and testing due to smaller, cleaner inputs.</li>
				</ul>
We observed that models trained on preprocessed images performed significantly better than those trained on raw RGB images, particularly in terms of training time and classification accuracy.
We also noticed that some images classes had very few images, which made it difficult for the model to learn from them. To address this, we filtered the dataset to include only those classes with a minimum of 80 images. This ensured that our model had enough data to learn from and improved its overall performance.

			</p>
		</div>
		<div class="project-container">
			<h2 id="knn">KNN algorithm <a style="font-size : medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/KNN_PRMLproj.ipynb" target="_blank">Code</a></h2>
			<hr>
				<h3>Introduction</h3>
				<p>
					The LFW dataset has varied number of images per person, some have very few images, while others have a large number of images.<br>
					Since, KNN does not require any training, instead, it calculates the distances of the test data point from all the training data points each time, hence, it gives nearly accurate predictions most of the times.

				</p>
				<hr>
				<h3>How we applied it</h3>
				<p>
					We assumed each pixel of image as a feature and trained our model on the LFW dataset. We used the decision tree algorithm to classify the images into classes i.e. each class for different person.
				</p>
				<hr>
				<h3>Results</h3>
				<p>
					best result is KNN on CNN + LBP features with lda keeping k=5:
					<ul>
						<li>Test Accuracy : 79.04%</li>
						<li>Train Accuracy :98.00%</li>
					</ul>
				</p>
		</div>
		<div class="project-container">
			<h2 id="nb">Naive Bayes algorithm<a style="font-size : medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/Naive_bayes_PRML_project.ipynb" target="_blank">Code</a></h2>
				<h3>Introduction</h3>
				<p>
Naive Bayes is a probabilistic classifier based on Bayes' Theorem, since features are conditionally independent given the class label. It's simple, fast, and works well with high-dimensional data
				</p>
				<hr>
				<h3>How we applied it</h3>
				To use Naive Bayes on  dataset with LBP and CNN features we train the Naive Bayes classifier on them to predict identities. Each feature vector (LBP/CNN) is treated as input, and the model learns the probability distribution over identities.
				<p>
				</p>
				<hr>
				<h3>Results</h3>
				<p>

					best result is on CNN features :
					<ul>
						<li>Test Accuracy : 0.39</li>
						<li>Train Accuracy :0.57</li>
					</ul>
				</p>
		</div>
		<div class="project-container">
			<h2 id="dt">Decision Tree algorithm <a style="font-size: medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/Decision_Tree_PRMLproj.ipynb" target="_blank">Code</a></h2>
				<hr>
				<h3>Introduction</h3>
				<p>
				 Decision Tree algorithm belongs to the family of supervised learning algorithms. Unlike other supervised learning algorithms, the decision tree algorithm can be used for solving regression and classification problems too.
				</p>
				<hr>
				<h3>How we applied it</h3>
				<p>
					To use a Decision Tree on the LFW dataset with LBP and CNN features, begin by preprocessing the images to extract these features — LBP captures local texture patterns, while CNN features encode deeper, high-level representations.rain the Decision Tree classifier on the training set by recursively partitioning the feature space to maximize class purity.The model learns patterns that differentiate between individual identities
				</p>
				<hr>
				<h3>Results</h3>
				<p>
					best result is on CNN features with max depth of 6 :
					<ul>
						<li>Test Accuracy : 0.75</li>
						<li>Train Accuracy :0.99</li>
					</ul>

				</p>
		</div>
		<div class="project-container">
			<h2 id="svm">Support Vector Machine algorithm <a style="font-size: medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/SVM_prml_project.ipynb" target="_blank">Code</a></h2>
			<hr>
				<h3>Introduction</h3>
				<p>
					Support Vector Machines (SVMs) are powerful supervised learning algorithms used for face identification by separating facial images into distinct classes. In this context, SVMs can model dissimilarities between faces in a "difference space," distinguishing between images of the same person and those of different individuals
				</p>
				<hr>
				<h3>How we applied it</h3>
				<p>
					first extract the features from each face image.Normalize or scale the features to ensure effective training. Choose an appropriate kernel (linear or RBF) depending on the data distribution. Train the SVM classifier on the labeled feature vectors, where the model finds the optimal hyperplane (or decision boundary) that separates identities with the maximum margin.
				</p>
				<hr>
				<h3>Results</h3>
				<p>
					best result is on CNN features  :
					<ul>
						<li>Test Accuracy : </li>
						<li>Train Accuracy :</li>
					</ul>
				</p>
		</div>

	<div class="project-container">
			<h2 id="svm">Random Forest <a style="font-size: medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/Random_forest.ipynb" target="_blank">Code</a></h2>
			<hr>
				<h3>Introduction</h3>
				<p>
				Random Forests, an ensemble learning method, combine multiple decision trees to enhance accuracy and robustness in face identification tasks. In face recognition, they handle variations in pose, illumination, and expression by analyzing features like LBP textures or CNN-derived semantic patterns.
				</p>
				<hr>
				<h3>How we applied it</h3>
				<p>
					irst extract these features from the images to form structured input vectors. Random Forest, an ensemble of Decision Trees, is then trained on these features — each tree learns to classify identities using random subsets of data and features, improving generalization and reducing overfitting.The final prediction is made through majority voting among the trees
				</p>
				<hr>
				<h3>Results</h3>
				<p>
					best result is on CNN features on applying LDA :
					<ul>
						<li>Test Accuracy :0.802 </li>
						<li>Train Accuracy :1.00</li>
					</ul>
				</p>
		</div>
	<div class="project-container">
			<h2 id="svm">Clustering <a style="font-size: medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/Clustering_PRMLproj.ipynb" target="_blank">Code</a></h2>
			<hr>
				<h3>Introduction</h3>
				<p>
					Clustering in face identification groups unlabeled facial images into distinct clusters, each representing a unique individual, using unsupervised learning
				</p>
				<hr>
				<h3>How we applied it</h3>
				<p>
					after extracting features and applying LDA,Since clustering is unsupervised, no identity labels are used during training. Apply a clustering algorithm like K-Means to group similar faces based on feature similarity
				</p>
				<hr>
				<h3>Results</h3>
				<p>
						best result is on CNN features with LDA:
					<ul>
						<li>Test Accuracy : 77% </li>
						<li>Train Accuracy :100%</li>
					</ul>
				</p>
	</div>
		<div class="project-container">
			<h2 id="svm">ANN <a style="font-size: medium;" href="https://github.com/AgarwalMayank2/Face_Detection/blob/main/applying_ML_algorithms/ann_main.ipynb" target="_blank">Code</a></h2>
			<hr>
				<h3>Introduction</h3>
				<p>
					{write in brief about your algo and why this is helpful} <br>
					e.g. Decision Tree algorithm belongs to the family of supervised learning algorithms. Unlike other supervised learning algorithms, the decision tree algorithm can be used for solving regression and classification problems too.
				</p>
				<hr>
				<h3>How we applied it</h3>
				<p>
					extract and normalize these features to form input vectors.then a feedforward neural network with input size matching the feature dimension, hidden layers to learn complex patterns, and an output layer with neurons equal to the number of unique identities. Training the ANN using a labeled dataset, optimizing a loss function like cross-entropy via backpropagation.
				</p>
				<hr>
				<h3>Results</h3>
				<p>
						best result is on CNN features with LDA:
					<ul>
						<li>Test Accuracy : 79.33% </li>
						<li>Train Accuracy :100%</li>
					</ul>
				</p>
		</div>

		<div class="project-container">
			<h2 id="dt">Results</h2>
				<hr>
				<div class = "image1">
					
				<img src="images/result1.png" alt="result1" height="500px" >
				</div>	
				
		</div>
		<div class="project-container">
			<h2 id="dt">Web demo</h2>
				<hr>
				<div class = "demo1">
					
				<img src="images/web1.png" alt="result1" height="500px" >
				</div>	
			
				<div class = "demo2">
					
				<img src="images/web2.png" alt="result1" height="500px" >
				</div>		
		</div>
</body>
</html>
